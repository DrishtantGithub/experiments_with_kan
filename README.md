KAN-Enhanced Deep Learning: Robust, Interpretable, and Efficient Models

This repository contains the full implementation, experiments, and analysis for our EE782 Advanced ML Final Project, where we build, extend, and analyze Kolmogorovâ€“Arnold Networks (KANs) across multiple domains â€” vision, NLP, tabular regression, and toy function approximation â€” and benchmark them against classical architectures (MLP & CNN).

We further introduce a Residual KAN Head, perform extensive ablation, robustness, interpretability, and efficiency analyses, and provide a clean modular codebase suitable for further research.

ðŸš€ Project Highlights
âœ” Unified KAN Benchmarking Across Modalities

Toy Regression (sinusoid)

CIFAR-10 image classification

IMDB sentiment analysis

Housing & Energy tabular regression tasks

âœ” Novel Architecture

We introduce a Residual KAN Head for CNNs:

combines linear skip connections

stabilizes spline curvature

improves robustness + efficiency

âœ” Deep Experimental Suite

We perform:

Knot Ablations (1, 3, 5, 7 knots)

Spline Curvature Regularization Ablation

Noise Robustness Experiments

Low-Data Generalization

Efficiency (Params, MACs, Latency, Model Size)

Full Interpretability:

Spline visualization

Derivative smoothness

Knot importance

Activation Patterns

Locality measurements

âœ” Reproducible Pipelines

Every experiment is runnable end-to-end using:

python -m src.train....
python -m src.analysis....
python -m src.robustness....

ðŸ“‚ Repository Structure
kan_project/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/                 # MLP, CNN, KAN, Residual KAN
â”‚   â”œâ”€â”€ train/                  # Training scripts for toy, CIFAR, NLP, tabular
â”‚   â”œâ”€â”€ analysis/               # Interpretability, spline plots, locality, activations
â”‚   â”œâ”€â”€ robustness/             # Noise & low-data robustness experiments
â”‚   â””â”€â”€ utils/                  # Data loaders, metrics, plotting helpers
â”‚
â”œâ”€â”€ results/                    # Saved trained models + experiment outputs
â”‚   â”œâ”€â”€ toy_kan/
â”‚   â”œâ”€â”€ cifar_relu/
â”‚   â”œâ”€â”€ cifar_kan/
â”‚   â”œâ”€â”€ cifar_residual/
â”‚   â”œâ”€â”€ interpretability/
â”‚   â”œâ”€â”€ robustness/
â”‚   â”œâ”€â”€ tabular_housing/
â”‚   â”œâ”€â”€ tabular_energy/
â”‚   â””â”€â”€ nlp_imdb/
â”‚
â”œâ”€â”€ paper/                      # LaTeX source for IEEE paper
â”‚   â”œâ”€â”€ Images/
â”‚   â””â”€â”€ sections/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ environment.yml
â””â”€â”€ README.md

ðŸ§ª How to Run Experiments
1. Create Environment
conda create -n kan python=3.10
pip install -r requirements.txt

ðŸŽ¯ Training Pipelines
âž¤ Toy Regression (Sinusoid)

KAN:

python -m src.train.train_toy --activation kan --save_dir ./results/toy_kan


ReLU MLP:

python -m src.train.train_toy --activation relu --save_dir ./results/toy_relu

âž¤ CIFAR-10 Classification
Baseline CNN
python -m src.train.train_cifar --activation relu --save_dir ./results/cifar_relu

CNN + KAN Head
python -m src.train.train_cifar --activation kan --save_dir ./results/cifar_kan

CNN + Residual KAN Head
python -m src.train.train_cifar_residual --head residual_kan --save_dir ./results/cifar_residual/residual_kan

âž¤ IMDB Sentiment Classification
python -m src.nlp.train_imdb --save_dir ./results/nlp_imdb

âž¤ Tabular Regression (Housing & Energy)
python -m src.train.train_tabular --dataset housing
python -m src.train.train_tabular --dataset energy

ðŸ“Š Analysis Pipelines
âž¤ Spline Visualization
python -m src.analysis.plot_splines \
  --model results/cifar_kan/cifar_model.pth \
  --model-type cnn \
  --save-dir results/interpretability/splines

âž¤ Knot Sensitivity
python -m src.analysis.knot_sensitivity \
  --model results/toy_kan/toy_model.pth \
  --dataset toy

âž¤ Locality and Support Width
python -m src.analysis.locality \
  --model results/cifar_kan/cifar_model.pth \
  --dataset cifar

âž¤ Activation Patterns
python -m src.analysis.activation_response \
  --kan-model results/cifar_kan/cifar_model.pth \
  --baseline-model results/cifar_relu/cifar_model.pth

ðŸ›¡ Robustness Experiments
âž¤ Noise Robustness
python -m src.robustness.noise_robustness \
  --toy-kan results/toy_kan/toy_model.pth \
  --cifar-kan results/cifar_kan/cifar_model.pth

âž¤ Low Data Robustness
python -m src.robustness.low_data \
  --cifar-kan results/cifar_kan/cifar_model.pth

âš¡ Efficiency Evaluation

Compute:

params

MACs

forward-time latency

model size

python -m src.analysis.compute_efficiency
python -m src.analysis.add_residual_to_efficiency

ðŸ“ˆ Key Findings
âœ” KAN consistently outperforms MLP and CNN on regression
âœ” Residual KAN beats all models on CIFAR-10 (especially noise & low-data)
âœ” Splines are interpretable: smooth derivatives, distinct knot importance
âœ” KAN activations show strong locality â†’ better interpretability
âœ” Efficiency close to CNN despite higher flexibility
ðŸ§© Interpretability Gallery (Available in /results)

Spline functions

Spline derivatives

Knot gradient importance

Activation heatmaps

Locality histograms

Support width histograms

Noise curves

Low-data curves

Efficiency bar charts

All included inside results/interpretability.
